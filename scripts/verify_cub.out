## SLURM PROLOG ###############################################################
##    Job ID : 11407174
##  Job Name : run_train_test.sh
##  Nodelist : gpu2002
##      CPUs : 
##  Mem/Node : 65536 MB
## Directory : /gpfs_home/xcao1/UDML_SS/scripts
##   Started : Sat Mar 28 11:31:57 EDT 2020
###############################################################################
module: loading 'gcc/7.2'
module: gcc: "Note: loading the gcc module overrides the gcc version on the system.  If you want to revert to the version of gcc provided by the OS, unload the gcc module."
module: loading 'anaconda/3-5.2.0'
module: loading 'cuda/10.0.130'
module: loading 'cudnn/7.4'
module: cudnn: To use: module load cuda/10.0.130
Begin Training!
25396838400
Namespace(alpha=40, batch_size=80, beta=2.0, corruption=0, data='cub', data_root='/gpfs/data/xl6/xuefei/ML/data', dim=512, epochs=600, freeze_BN=True, gallery_eq_query=True, init='random', k=16, loss='Weight', loss_base=0.75, lr=1e-05, margin=0.5, momentum=0.9, nThreads=16, net='Inception', num_clusters=100, num_instances=5, origin_width=256, orth_reg=0, pool_feature=False, pretrained=True, print_freq=20, ratio=0.16, resume='yes', rot_batch=16, rot_bt=1, rot_lr=1e-05, rot_only=0.0, save_dir='/gpfs/data/xl6/xuefei/ML/results/Deep_Metric/ckpt/Weight/cub/Inception-DIM-512-lr-0.00001-ratio-0.16-BatchSize-80-rot_lr-0.00001-self_supervision_rot-0.1-rot_bt-1-rot_batch-16-up_step-5-num_clusters-100-ALPHA-40-BETA-2', save_step=50, self_supervision_rot=0.1, up_step=5, use_test=0.0, weight_decay=0.0005, width=227)
Learn Rate  	1.0e-05
Epochs  	00600
Log Path 	/gpfs/data/xl6/xuefei/ML/results/Deep_Metric/ckpt/Weight/cub/Inception-DIM-512-lr-0.00001-ratio-0.16-BatchSize-80-rot_lr-0.00001-self_supervision_rot-0.1-rot_bt-1-rot_batch-16-up_step-5-num_clusters-100-ALPHA-40-BETA-2
Network 	 Inception
Data Set 	 cub
Batch Size  	 80
Num-Instance  	 5
Embedded Dimension 	 512
Loss Function 	Weight
Alpha 	 40
Begin to fine tune Inception Network
########################################
Sequential(
  (0): Linear(in_features=1024, out_features=512, bias=True)
  (1): ReLU(inplace=True)
  (2): Linear(in_features=512, out_features=4, bias=True)
  (3): ReLU(inplace=True)
)
loaded++++++++++++++++++++++++++++++++++
dict_keys(['inception_3a.3x3_reduce.bias', 'inception_4e.1x1.bias', 'inception_4b.1x1.bias', 'inception_4a.pool_proj.weight', 'inception_4d.1x1.weight', 'inception_3b.pool_proj.bias', 'inception_4e.1x1.weight', 'inception_4d.5x5_reduce.weight', 'inception_4b.pool_proj.weight', 'inception_3a.3x3.bias', 'inception_4b.3x3.bias', 'inception_3b.5x5_reduce.weight', 'inception_4a.1x1.bias', 'inception_3b.1x1.weight', 'inception_5b.5x5_reduce.weight', 'inception_4e.5x5.bias', 'inception_4d.1x1.bias', 'inception_4d.5x5.bias', 'inception_3b.3x3_reduce.weight', 'inception_5b.3x3.bias', 'inception_3a.pool_proj.weight', 'inception_4c.5x5_reduce.bias', 'inception_3b.3x3.bias', 'inception_5a.3x3_reduce.weight', 'inception_4e.pool_proj.weight', 'inception_4a.1x1.weight', 'inception_4e.3x3.weight', 'inception_5b.3x3_reduce.bias', 'inception_4a.5x5_reduce.weight', 'inception_4a.5x5_reduce.bias', 'inception_5a.3x3.weight', 'inception_4c.3x3.weight', 'inception_4e.5x5_reduce.bias', 'inception_4c.5x5.weight', 'inception_4a.3x3.bias', 'inception_4c.pool_proj.bias', 'inception_4d.3x3.bias', 'conv1.7x7_s2.bias', 'inception_4b.1x1.weight', 'inception_4a.pool_proj.bias', 'inception_4b.3x3_reduce.weight', 'inception_5b.5x5.bias', 'inception_3a.5x5_reduce.bias', 'inception_5a.1x1.bias', 'inception_4d.pool_proj.bias', 'conv2.3x3_reduce.bias', 'inception_4a.3x3.weight', 'inception_4d.3x3_reduce.weight', 'inception_5a.5x5_reduce.weight', 'inception_3b.5x5_reduce.bias', 'inception_4b.3x3_reduce.bias', 'inception_3a.3x3.weight', 'inception_4c.3x3_reduce.bias', 'inception_5a.3x3.bias', 'inception_4d.3x3.weight', 'inception_5b.1x1.bias', 'inception_4a.5x5.weight', 'inception_3b.3x3_reduce.bias', 'inception_4a.3x3_reduce.weight', 'inception_3a.1x1.weight', 'inception_5a.5x5_reduce.bias', 'inception_4d.pool_proj.weight', 'inception_3b.1x1.bias', 'inception_4b.5x5_reduce.weight', 'inception_3b.3x3.weight', 'inception_4c.3x3_reduce.weight', 'inception_5b.1x1.weight', 'inception_5b.5x5_reduce.bias', 'inception_4c.5x5_reduce.weight', 'inception_5b.5x5.weight', 'inception_5a.5x5.bias', 'conv1.7x7_s2.weight', 'inception_3b.5x5.weight', 'inception_3a.1x1.bias', 'inception_4c.pool_proj.weight', 'inception_4e.3x3_reduce.weight', 'inception_5a.1x1.weight', 'inception_4c.1x1.weight', 'inception_5b.pool_proj.bias', 'inception_4e.5x5.weight', 'inception_4d.5x5_reduce.bias', 'inception_4b.5x5_reduce.bias', 'inception_4e.3x3.bias', 'inception_5a.pool_proj.bias', 'inception_3b.5x5.bias', 'inception_4b.5x5.bias', 'inception_4e.3x3_reduce.bias', 'inception_4e.pool_proj.bias', 'inception_5b.3x3.weight', 'conv2.3x3.bias', 'inception_5b.3x3_reduce.weight', 'inception_3a.5x5.bias', 'inception_5a.3x3_reduce.bias', 'inception_3a.pool_proj.bias', 'inception_5a.5x5.weight', 'inception_4d.3x3_reduce.bias', 'inception_4c.5x5.bias', 'inception_4b.pool_proj.bias', 'inception_4b.3x3.weight', 'inception_3a.3x3_reduce.weight', 'inception_4c.3x3.bias', 'conv2.3x3_reduce.weight', 'inception_4e.5x5_reduce.weight', 'inception_5b.pool_proj.weight', 'inception_3a.5x5_reduce.weight', 'inception_4c.1x1.bias', 'inception_3b.pool_proj.weight', 'inception_4a.3x3_reduce.bias', 'inception_5a.pool_proj.weight', 'inception_4b.5x5.weight', 'inception_3a.5x5.weight', 'conv2.3x3.weight', 'inception_4a.5x5.bias', 'inception_4d.5x5.weight'])
114
finished
width: 	 227
bgr init
train.txt is used!
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff84ec3bba8>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff84ec3bba8>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    CenterCrop(size=(227, 227))
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
Extract Features: [59/59]	Time 0.020 (0.020)	Data 23.561 (23.561)	
torch.Size([5864, 1024]) <class 'torch.Tensor'>
